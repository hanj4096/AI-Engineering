{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Reflection (LangChain 代码示例)\n",
    "\n",
    "本 notebook 演示了如何使用 LangChain 实现 Reflection（反思）模式，通过生成-批判-改进的链式流程来优化产品描述。\n",
    "\n",
    "## 前置要求\n",
    "\n",
    "- Python 3.8+\n",
    "- 阿里云 DashScope API Key（需要设置环境变量 `DASHSCOPE_API_KEY`）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装依赖\n",
    "\n",
    "首先安装所需的 Python 包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装必要的依赖包（使用 %pip 在 Jupyter 中更推荐）\n",
    "%pip install -q langchain-core>=0.1.0 langchain-community>=0.1.0 dashscope>=1.17.0 python-dotenv>=1.0.0 nest-asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 获取 API Key\n",
    "\n",
    "如果环境变量或 .env 文件中没有设置 `DASHSCOPE_API_KEY`，可以在此处直接设置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 获取 API key（优先从环境变量读取，如果没有则从 .env 文件）\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "if not dashscope_api_key:\n",
    "    print(\"警告：未找到 DASHSCOPE_API_KEY，请确保已设置环境变量或 .env 文件\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 导入库并初始化模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3NBB8hsfc7iJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language model initialized: qwen-flash\n",
      "\n",
      "--- Running Reflection Example for Product: 'A mug that keeps coffee hot and can be controlled by a smartphone app.' ---\n",
      "\n",
      "--- Final Refined Product Description ---\n",
      "**SmartSip Mug – Your Coffee, Perfectly Hot, Every Time.**\n",
      "\n",
      "No more cold coffee by 10 a.m. With double-wall vacuum insulation and intelligent heating, SmartSip keeps your brew steaming for up to 4 hours—starting from the moment you pour it in.\n",
      "\n",
      "Control it with your phone: set your ideal temperature (120°F–160°F), schedule warming bursts, or get a gentle reminder when it’s just right. Whether you’re deep in a work session, on a morning commute, or hiking through the woods, your coffee stays at peak warmth—no guesswork, no disappointment.\n",
      "\n",
      "Lightweight, sleek, and built for real life.  \n",
      "Wake up to a perfect cup. Stay warm. Stay focused. Stay inspired.\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ Why This Works:\n",
      "- **Clear, specific benefits:** “From the moment you pour” removes ambiguity; “120°F–160°F” adds precision and trust.\n",
      "- **Solves real pain points:** Addresses cold coffee, inconsistent temps, and forgetfulness.\n",
      "- **Emotional resonance:** Ties into daily routines—work, travel, outdoor adventures—with relatable moments.\n",
      "- **Concise & compelling:** No fluff. Every sentence drives value.\n",
      "- **Strong closing:** Ends with inspiration, not just a tagline.\n",
      "\n",
      "> *The best part? You don’t just keep coffee hot—you take control of your day, one perfect sip at a time.*\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 允许在 Jupyter notebook 中运行异步代码\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "# 初始化 Qwen 语言模型（使用阿里云 DashScope API）\n",
    "# model 参数可以指定不同的 Qwen 模型，如 \"qwen-flash\", \"qwen-turbo\", \"qwen-plus\", \"qwen-max\" 等\n",
    "try:\n",
    "    llm = ChatTongyi(\n",
    "        model=\"qwen-flash\",\n",
    "        temperature=0.7,\n",
    "        dashscope_api_key=dashscope_api_key\n",
    "    )\n",
    "    print(f\"Language model initialized: qwen-flash\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing language model: {e}\")\n",
    "    print(\"Please ensure your DASHSCOPE_API_KEY is set correctly.\")\n",
    "    llm = None\n",
    "\n",
    "\n",
    "# --- Define Chain Components ---\n",
    "\n",
    "# 1. Initial Generation: Creates the first draft of the product description.\n",
    "# The input to this chain will be a dictionary, so we update the prompt template.\n",
    "generation_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Write a short, simple product description for a new smart coffee mug.\"),\n",
    "        (\"user\", \"{product_details}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2. Critique: Evaluates the generated description and provides feedback.\n",
    "critique_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Critique the following product description based on clarity, conciseness, and appeal.\n",
    "        Provide specific suggestions for improvement.\"\"\"),\n",
    "        # This will receive 'initial_description' from the previous step.\n",
    "        (\"user\", \"Product Description to Critique:\\n{initial_description}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 3. Refinement: Rewrites the description based on the original details and the critique.\n",
    "refinement_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Based on the original product details and the following critique,\n",
    "        rewrite the product description to be more effective.\n",
    "\n",
    "        Original Product Details: {product_details}\n",
    "        Critique: {critique}\n",
    "\n",
    "        Refined Product Description:\"\"\"),\n",
    "        (\"user\", \"\") # User input is empty as the context is provided in the system message\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# --- Build the Full Reflection Chain (Refactored) ---\n",
    "# This chain is structured to be more readable and linear.\n",
    "full_reflection_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        initial_description=generation_chain\n",
    "    )\n",
    "    | RunnablePassthrough.assign(\n",
    "        critique=critique_chain\n",
    "    )\n",
    "    | refinement_chain\n",
    ")\n",
    "\n",
    "\n",
    "# --- Run the Chain ---\n",
    "async def run_reflection_example(product_details: str):\n",
    "    \"\"\"Runs the LangChain reflection example with product details.\"\"\"\n",
    "    if not llm:\n",
    "        print(\"LLM 未初始化，无法运行反思示例。请检查 API key 配置。\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n--- Running Reflection Example for Product: '{product_details}' ---\")\n",
    "    try:\n",
    "        # The chain now expects a dictionary as input from the start.\n",
    "        final_refined_description = await full_reflection_chain.ainvoke(\n",
    "            {\"product_details\": product_details}\n",
    "        )\n",
    "        print(\"\\n--- Final Refined Product Description ---\")\n",
    "        print(final_refined_description)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during chain execution: {e}\")\n",
    "\n",
    "# 运行反思示例\n",
    "# 在 Jupyter notebook 中，可以直接使用 await run_reflection_example(test_product_details)\n",
    "# 或者使用 asyncio.run()（需要 nest_asyncio 支持）\n",
    "if llm:\n",
    "    test_product_details = \"A mug that keeps coffee hot and can be controlled by a smartphone app.\"\n",
    "    asyncio.run(run_reflection_example(test_product_details))\n",
    "else:\n",
    "    print(\"LLM 未初始化，无法运行示例。请检查 API key 配置。\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
