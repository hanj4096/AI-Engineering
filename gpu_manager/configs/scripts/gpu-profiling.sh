#!/bin/bash
# GPUæ€§èƒ½åˆ†æè„šæœ¬
# æä¾›å…¨é¢çš„GPUæ€§èƒ½åˆ†æå’Œè°ƒä¼˜å·¥å…·

set -e

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# é…ç½®å˜é‡
PROFILE_DURATION=60
OUTPUT_DIR="gpu_profiling_$(date +%Y%m%d_%H%M%S)"
LOG_FILE="$OUTPUT_DIR/profiling.log"
REPORT_FILE="$OUTPUT_DIR/profiling_report.md"
SAMPLE_INTERVAL=1
PROFILE_TYPE="all"
TARGET_PID=""
TARGET_COMMAND=""

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1" | tee -a "$LOG_FILE"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$LOG_FILE"
}

log_debug() {
    echo -e "${BLUE}[DEBUG]${NC} $1" | tee -a "$LOG_FILE"
}

log_section() {
    echo -e "${PURPLE}[SECTION]${NC} $1" | tee -a "$LOG_FILE"
}

# åˆ›å»ºè¾“å‡ºç›®å½•
setup_output_directory() {
    mkdir -p "$OUTPUT_DIR"
    log_info "æ€§èƒ½åˆ†æç»“æœå°†ä¿å­˜åˆ°: $OUTPUT_DIR"
}

# æ£€æŸ¥ä¾èµ–å·¥å…·
check_dependencies() {
    log_info "æ£€æŸ¥ä¾èµ–å·¥å…·..."
    
    local missing_tools=()
    
    # å¿…éœ€å·¥å…·
    if ! command -v nvidia-smi &> /dev/null; then
        missing_tools+=("nvidia-smi")
    fi
    
    # å¯é€‰å·¥å…·
    local optional_tools=("nvtop" "gpustat" "nvprof" "nsys" "ncu" "nvidia-ml-py")
    local available_tools=()
    
    for tool in "${optional_tools[@]}"; do
        if command -v "$tool" &> /dev/null; then
            available_tools+=("$tool")
        fi
    done
    
    if [[ ${#missing_tools[@]} -gt 0 ]]; then
        log_error "ç¼ºå°‘å¿…éœ€å·¥å…·: ${missing_tools[*]}"
        return 1
    fi
    
    log_info "å¯ç”¨çš„æ€§èƒ½åˆ†æå·¥å…·: ${available_tools[*]}"
    
    # æ£€æŸ¥Pythonå·¥å…·
    if command -v python3 &> /dev/null; then
        python3 -c "import pynvml" 2>/dev/null && log_info "pynvmlå¯ç”¨" || log_warn "pynvmlä¸å¯ç”¨"
        python3 -c "import GPUtil" 2>/dev/null && log_info "GPUtilå¯ç”¨" || log_warn "GPUtilä¸å¯ç”¨"
    fi
    
    log_info "âœ… ä¾èµ–æ£€æŸ¥å®Œæˆ"
}

# GPUåŸºç¡€ä¿¡æ¯æ”¶é›†
collect_gpu_info() {
    log_section "æ”¶é›†GPUåŸºç¡€ä¿¡æ¯"
    
    # GPUè®¾å¤‡ä¿¡æ¯
    log_info "GPUè®¾å¤‡ä¿¡æ¯:"
    nvidia-smi --query-gpu=index,name,memory.total,memory.free,memory.used,utilization.gpu,utilization.memory,temperature.gpu,power.draw,power.limit,clocks.gr,clocks.mem,compute_cap --format=csv > "$OUTPUT_DIR/gpu_info.csv"
    
    # æ˜¾ç¤ºæ‘˜è¦
    nvidia-smi --query-gpu=index,name,memory.total,compute_cap --format=csv,noheader | while IFS=',' read -r index name memory compute_cap; do
        log_info "GPU $index: $name, å†…å­˜: $memory, è®¡ç®—èƒ½åŠ›: $compute_cap"
    done
    
    # é©±åŠ¨å’ŒCUDAä¿¡æ¯
    local driver_version=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1)
    log_info "NVIDIAé©±åŠ¨ç‰ˆæœ¬: $driver_version"
    
    if command -v nvcc &> /dev/null; then
        local cuda_version=$(nvcc --version | grep "release" | awk '{print $6}' | cut -c2-)
        log_info "CUDAç‰ˆæœ¬: $cuda_version"
    fi
    
    # GPUæ‹“æ‰‘ä¿¡æ¯
    if nvidia-smi topo -m &> /dev/null; then
        log_info "GPUæ‹“æ‰‘ä¿¡æ¯:"
        nvidia-smi topo -m > "$OUTPUT_DIR/gpu_topology.txt" 2>/dev/null || log_warn "æ— æ³•è·å–GPUæ‹“æ‰‘ä¿¡æ¯"
    fi
    
    log_info "âœ… GPUåŸºç¡€ä¿¡æ¯æ”¶é›†å®Œæˆ"
}

# å®æ—¶GPUç›‘æ§
real_time_monitoring() {
    log_section "å¼€å§‹å®æ—¶GPUç›‘æ§ (${PROFILE_DURATION}ç§’)"
    
    # åˆ›å»ºç›‘æ§è„šæœ¬
    cat > "$OUTPUT_DIR/monitor_gpu.py" << 'EOF'
import time
import csv
import subprocess
import sys
from datetime import datetime

def get_gpu_stats():
    """è·å–GPUç»Ÿè®¡ä¿¡æ¯"""
    try:
        result = subprocess.run([
            'nvidia-smi',
            '--query-gpu=timestamp,index,name,utilization.gpu,utilization.memory,memory.total,memory.used,memory.free,temperature.gpu,power.draw,clocks.gr,clocks.mem',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, check=True)
        
        return result.stdout.strip().split('\n')
    except subprocess.CalledProcessError as e:
        print(f"é”™è¯¯: {e}")
        return []

def get_process_stats():
    """è·å–GPUè¿›ç¨‹ä¿¡æ¯"""
    try:
        result = subprocess.run([
            'nvidia-smi',
            '--query-compute-apps=pid,process_name,gpu_uuid,used_memory',
            '--format=csv,noheader'
        ], capture_output=True, text=True, check=True)
        
        return result.stdout.strip().split('\n') if result.stdout.strip() else []
    except subprocess.CalledProcessError:
        return []

def monitor_gpu(duration, interval, output_file):
    """ç›‘æ§GPUæ€§èƒ½"""
    print(f"å¼€å§‹ç›‘æ§GPUæ€§èƒ½ï¼ŒæŒç»­æ—¶é—´: {duration}ç§’ï¼Œé‡‡æ ·é—´éš”: {interval}ç§’")
    
    # å‡†å¤‡CSVæ–‡ä»¶
    with open(output_file, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([
            'timestamp', 'gpu_index', 'gpu_name', 'gpu_util_percent', 
            'memory_util_percent', 'memory_total_mb', 'memory_used_mb', 
            'memory_free_mb', 'temperature_c', 'power_draw_w', 
            'graphics_clock_mhz', 'memory_clock_mhz'
        ])
        
        start_time = time.time()
        sample_count = 0
        
        while time.time() - start_time < duration:
            gpu_stats = get_gpu_stats()
            
            for stat_line in gpu_stats:
                if stat_line.strip():
                    # è§£æç»Ÿè®¡ä¿¡æ¯
                    parts = [part.strip() for part in stat_line.split(',')]
                    if len(parts) >= 12:
                        writer.writerow(parts)
            
            sample_count += 1
            if sample_count % 10 == 0:
                print(f"å·²é‡‡æ · {sample_count} æ¬¡...")
            
            time.sleep(interval)
    
    print(f"ç›‘æ§å®Œæˆï¼Œå…±é‡‡æ · {sample_count} æ¬¡")

if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("ç”¨æ³•: python3 monitor_gpu.py <duration> <interval> <output_file>")
        sys.exit(1)
    
    duration = int(sys.argv[1])
    interval = float(sys.argv[2])
    output_file = sys.argv[3]
    
    monitor_gpu(duration, interval, output_file)
EOF
    
    # è¿è¡Œç›‘æ§
    if command -v python3 &> /dev/null; then
        log_info "å¯åŠ¨Pythonç›‘æ§è„šæœ¬..."
        python3 "$OUTPUT_DIR/monitor_gpu.py" "$PROFILE_DURATION" "$SAMPLE_INTERVAL" "$OUTPUT_DIR/gpu_monitoring.csv" &
        MONITOR_PID=$!
    fi
    
    # åŒæ—¶ä½¿ç”¨nvidia-smiè¿›è¡Œç›‘æ§
    log_info "å¯åŠ¨nvidia-smiç›‘æ§..."
    {
        echo "timestamp,gpu_util,memory_util,temperature,power_draw,graphics_clock,memory_clock"
        for ((i=0; i<PROFILE_DURATION; i++)); do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            local stats=$(nvidia-smi --query-gpu=utilization.gpu,utilization.memory,temperature.gpu,power.draw,clocks.gr,clocks.mem --format=csv,noheader,nounits | head -1)
            echo "$timestamp,$stats"
            sleep 1
        done
    } > "$OUTPUT_DIR/nvidia_smi_monitoring.csv" &
    NVIDIA_SMI_PID=$!
    
    # å¦‚æœæœ‰nvtopï¼Œä¹Ÿå¯åŠ¨å®ƒ
    if command -v nvtop &> /dev/null; then
        log_info "å¯åŠ¨nvtopç›‘æ§..."
        timeout "${PROFILE_DURATION}s" nvtop -d 1 > "$OUTPUT_DIR/nvtop_output.txt" 2>&1 &
        NVTOP_PID=$!
    fi
    
    # ç­‰å¾…ç›‘æ§å®Œæˆ
    log_info "ç›‘æ§è¿›è¡Œä¸­ï¼Œè¯·ç­‰å¾… ${PROFILE_DURATION} ç§’..."
    
    # æ˜¾ç¤ºè¿›åº¦æ¡
    for ((i=1; i<=PROFILE_DURATION; i++)); do
        printf "\rè¿›åº¦: [%-50s] %d%%" $(printf "#%.0s" $(seq 1 $((i*50/PROFILE_DURATION)))) $((i*100/PROFILE_DURATION))
        sleep 1
    done
    echo
    
    # ç­‰å¾…æ‰€æœ‰ç›‘æ§è¿›ç¨‹å®Œæˆ
    wait $NVIDIA_SMI_PID 2>/dev/null || true
    [[ -n "$MONITOR_PID" ]] && wait $MONITOR_PID 2>/dev/null || true
    [[ -n "$NVTOP_PID" ]] && kill $NVTOP_PID 2>/dev/null || true
    
    log_info "âœ… å®æ—¶ç›‘æ§å®Œæˆ"
}

# GPUè¿›ç¨‹åˆ†æ
analyze_gpu_processes() {
    log_section "åˆ†æGPUè¿›ç¨‹"
    
    # å½“å‰GPUè¿›ç¨‹
    log_info "å½“å‰GPUè¿›ç¨‹:"
    nvidia-smi pmon -c 1 > "$OUTPUT_DIR/gpu_processes.txt" 2>/dev/null || {
        nvidia-smi --query-compute-apps=pid,process_name,gpu_uuid,used_memory --format=csv > "$OUTPUT_DIR/gpu_processes.csv"
        log_info "GPUè¿›ç¨‹ä¿¡æ¯å·²ä¿å­˜åˆ° gpu_processes.csv"
    }
    
    # è¯¦ç»†è¿›ç¨‹ä¿¡æ¯
    if nvidia-smi --query-compute-apps=pid,process_name,gpu_uuid,used_memory --format=csv,noheader 2>/dev/null | grep -v "No running processes found"; then
        log_info "æ£€æµ‹åˆ°è¿è¡Œä¸­çš„GPUè¿›ç¨‹:"
        nvidia-smi --query-compute-apps=pid,process_name,gpu_uuid,used_memory --format=csv,noheader | while IFS=',' read -r pid process_name gpu_uuid used_memory; do
            if [[ -n "$pid" && "$pid" != "No running processes found" ]]; then
                log_info "PID: $pid, è¿›ç¨‹: $process_name, å†…å­˜ä½¿ç”¨: $used_memory"
                
                # è·å–è¿›ç¨‹è¯¦ç»†ä¿¡æ¯
                if ps -p "$pid" -o pid,ppid,user,cmd --no-headers 2>/dev/null; then
                    ps -p "$pid" -o pid,ppid,user,cmd --no-headers >> "$OUTPUT_DIR/process_details.txt"
                fi
            fi
        done
    else
        log_info "å½“å‰æ²¡æœ‰è¿è¡Œä¸­çš„GPUè¿›ç¨‹"
    fi
    
    log_info "âœ… GPUè¿›ç¨‹åˆ†æå®Œæˆ"
}

# å†…å­˜åˆ†æ
analyze_gpu_memory() {
    log_section "GPUå†…å­˜åˆ†æ"
    
    # å†…å­˜ä½¿ç”¨æƒ…å†µ
    log_info "GPUå†…å­˜ä½¿ç”¨æƒ…å†µ:"
    nvidia-smi --query-gpu=index,memory.total,memory.used,memory.free --format=csv > "$OUTPUT_DIR/memory_usage.csv"
    
    # æ˜¾ç¤ºå†…å­˜æ‘˜è¦
    nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free --format=csv,noheader | while IFS=',' read -r index name total used free; do
        local used_percent=$(echo "scale=1; $used * 100 / $total" | bc 2>/dev/null || echo "N/A")
        log_info "GPU $index ($name): æ€»å†…å­˜ $total, å·²ç”¨ $used ($used_percent%), ç©ºé—² $free"
    done
    
    # å†…å­˜ç¢ç‰‡åˆ†æ
    if command -v python3 &> /dev/null; then
        cat > "$OUTPUT_DIR/memory_analysis.py" << 'EOF'
import subprocess
import json

def analyze_memory_fragmentation():
    """åˆ†æGPUå†…å­˜ç¢ç‰‡"""
    try:
        # è·å–è¯¦ç»†å†…å­˜ä¿¡æ¯
        result = subprocess.run([
            'nvidia-smi', '--query-gpu=index,memory.total,memory.used,memory.free',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, check=True)
        
        memory_info = []
        for line in result.stdout.strip().split('\n'):
            if line.strip():
                parts = line.split(', ')
                if len(parts) >= 4:
                    index, total, used, free = parts
                    memory_info.append({
                        'gpu_index': int(index),
                        'total_mb': int(total),
                        'used_mb': int(used),
                        'free_mb': int(free),
                        'utilization_percent': round(int(used) * 100 / int(total), 2)
                    })
        
        # ä¿å­˜åˆ†æç»“æœ
        with open('memory_analysis.json', 'w') as f:
            json.dump(memory_info, f, indent=2)
        
        print("GPUå†…å­˜åˆ†æ:")
        for info in memory_info:
            print(f"GPU {info['gpu_index']}: {info['utilization_percent']}% ä½¿ç”¨ç‡")
            if info['utilization_percent'] > 90:
                print(f"  è­¦å‘Š: GPU {info['gpu_index']} å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜")
            elif info['utilization_percent'] < 10:
                print(f"  æç¤º: GPU {info['gpu_index']} å†…å­˜åˆ©ç”¨ç‡è¾ƒä½")
    
    except Exception as e:
        print(f"å†…å­˜åˆ†æå¤±è´¥: {e}")

if __name__ == "__main__":
    analyze_memory_fragmentation()
EOF
        
        cd "$OUTPUT_DIR"
        python3 memory_analysis.py
        cd - > /dev/null
    fi
    
    log_info "âœ… GPUå†…å­˜åˆ†æå®Œæˆ"
}

# æ€§èƒ½ç“¶é¢ˆåˆ†æ
analyze_performance_bottlenecks() {
    log_section "æ€§èƒ½ç“¶é¢ˆåˆ†æ"
    
    # åˆ†æç›‘æ§æ•°æ®
    if [[ -f "$OUTPUT_DIR/gpu_monitoring.csv" ]]; then
        log_info "åˆ†æGPUåˆ©ç”¨ç‡æ•°æ®..."
        
        # åˆ›å»ºåˆ†æè„šæœ¬
        cat > "$OUTPUT_DIR/bottleneck_analysis.py" << 'EOF'
import csv
import statistics
import json

def analyze_gpu_utilization(csv_file):
    """åˆ†æGPUåˆ©ç”¨ç‡æ•°æ®"""
    gpu_utils = []
    memory_utils = []
    temperatures = []
    power_draws = []
    
    try:
        with open(csv_file, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    gpu_util = float(row['gpu_util_percent'])
                    memory_util = float(row['memory_util_percent'])
                    temp = float(row['temperature_c'])
                    power = float(row['power_draw_w'])
                    
                    gpu_utils.append(gpu_util)
                    memory_utils.append(memory_util)
                    temperatures.append(temp)
                    power_draws.append(power)
                except (ValueError, KeyError):
                    continue
        
        if not gpu_utils:
            print("æ²¡æœ‰æœ‰æ•ˆçš„ç›‘æ§æ•°æ®")
            return
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        analysis = {
            'gpu_utilization': {
                'mean': round(statistics.mean(gpu_utils), 2),
                'median': round(statistics.median(gpu_utils), 2),
                'max': round(max(gpu_utils), 2),
                'min': round(min(gpu_utils), 2),
                'stdev': round(statistics.stdev(gpu_utils) if len(gpu_utils) > 1 else 0, 2)
            },
            'memory_utilization': {
                'mean': round(statistics.mean(memory_utils), 2),
                'median': round(statistics.median(memory_utils), 2),
                'max': round(max(memory_utils), 2),
                'min': round(min(memory_utils), 2),
                'stdev': round(statistics.stdev(memory_utils) if len(memory_utils) > 1 else 0, 2)
            },
            'temperature': {
                'mean': round(statistics.mean(temperatures), 2),
                'max': round(max(temperatures), 2),
                'min': round(min(temperatures), 2)
            },
            'power_draw': {
                'mean': round(statistics.mean(power_draws), 2),
                'max': round(max(power_draws), 2),
                'min': round(min(power_draws), 2)
            }
        }
        
        # ç“¶é¢ˆåˆ†æ
        bottlenecks = []
        recommendations = []
        
        # GPUåˆ©ç”¨ç‡åˆ†æ
        if analysis['gpu_utilization']['mean'] < 50:
            bottlenecks.append("GPUåˆ©ç”¨ç‡ä½")
            recommendations.append("è€ƒè™‘å¢åŠ æ‰¹æ¬¡å¤§å°æˆ–ä¼˜åŒ–æ•°æ®åŠ è½½")
        elif analysis['gpu_utilization']['mean'] > 95:
            bottlenecks.append("GPUåˆ©ç”¨ç‡è¿‡é«˜")
            recommendations.append("å¯èƒ½éœ€è¦æ›´å¼ºçš„GPUæˆ–ä¼˜åŒ–ç®—æ³•")
        
        # å†…å­˜åˆ©ç”¨ç‡åˆ†æ
        if analysis['memory_utilization']['mean'] > 90:
            bottlenecks.append("GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜")
            recommendations.append("è€ƒè™‘å‡å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯")
        elif analysis['memory_utilization']['mean'] < 30:
            bottlenecks.append("GPUå†…å­˜åˆ©ç”¨ç‡ä½")
            recommendations.append("å¯ä»¥å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜æ•ˆç‡")
        
        # æ¸©åº¦åˆ†æ
        if analysis['temperature']['max'] > 80:
            bottlenecks.append("GPUæ¸©åº¦è¿‡é«˜")
            recommendations.append("æ£€æŸ¥æ•£çƒ­ç³»ç»Ÿï¼Œè€ƒè™‘é™ä½åŠŸè€—é™åˆ¶")
        
        # åŠŸè€—åˆ†æ
        if analysis['power_draw']['mean'] > 250:  # å‡è®¾åŠŸè€—é™åˆ¶
            bottlenecks.append("åŠŸè€—è¾ƒé«˜")
            recommendations.append("è€ƒè™‘ä¼˜åŒ–ç®—æ³•æˆ–è°ƒæ•´åŠŸè€—é™åˆ¶")
        
        analysis['bottlenecks'] = bottlenecks
        analysis['recommendations'] = recommendations
        
        # ä¿å­˜åˆ†æç»“æœ
        with open('bottleneck_analysis.json', 'w') as f:
            json.dump(analysis, f, indent=2)
        
        # æ‰“å°ç»“æœ
        print("=== GPUæ€§èƒ½ç“¶é¢ˆåˆ†æ ===")
        print(f"GPUå¹³å‡åˆ©ç”¨ç‡: {analysis['gpu_utilization']['mean']}%")
        print(f"å†…å­˜å¹³å‡åˆ©ç”¨ç‡: {analysis['memory_utilization']['mean']}%")
        print(f"å¹³å‡æ¸©åº¦: {analysis['temperature']['mean']}Â°C")
        print(f"å¹³å‡åŠŸè€—: {analysis['power_draw']['mean']}W")
        
        if bottlenecks:
            print("\næ£€æµ‹åˆ°çš„ç“¶é¢ˆ:")
            for bottleneck in bottlenecks:
                print(f"- {bottleneck}")
        
        if recommendations:
            print("\nä¼˜åŒ–å»ºè®®:")
            for rec in recommendations:
                print(f"- {rec}")
    
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")

if __name__ == "__main__":
    analyze_gpu_utilization('gpu_monitoring.csv')
EOF
        
        cd "$OUTPUT_DIR"
        python3 bottleneck_analysis.py
        cd - > /dev/null
    fi
    
    log_info "âœ… æ€§èƒ½ç“¶é¢ˆåˆ†æå®Œæˆ"
}

# CUDAåˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
cuda_profiling() {
    if [[ -z "$TARGET_COMMAND" ]]; then
        log_warn "è·³è¿‡CUDAåˆ†æï¼ˆæœªæŒ‡å®šç›®æ ‡å‘½ä»¤ï¼‰"
        return 0
    fi
    
    log_section "CUDAæ€§èƒ½åˆ†æ"
    
    # ä½¿ç”¨nsysè¿›è¡Œåˆ†æ
    if command -v nsys &> /dev/null; then
        log_info "ä½¿ç”¨Nsight Systemsè¿›è¡Œåˆ†æ..."
        nsys profile -o "$OUTPUT_DIR/nsys_profile" --stats=true $TARGET_COMMAND > "$OUTPUT_DIR/nsys_output.txt" 2>&1 || {
            log_warn "Nsight Systemsåˆ†æå¤±è´¥"
        }
    fi
    
    # ä½¿ç”¨ncuè¿›è¡Œåˆ†æ
    if command -v ncu &> /dev/null; then
        log_info "ä½¿ç”¨Nsight Computeè¿›è¡Œåˆ†æ..."
        ncu --set full -o "$OUTPUT_DIR/ncu_profile" $TARGET_COMMAND > "$OUTPUT_DIR/ncu_output.txt" 2>&1 || {
            log_warn "Nsight Computeåˆ†æå¤±è´¥"
        }
    fi
    
    # ä½¿ç”¨nvprofè¿›è¡Œåˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if command -v nvprof &> /dev/null; then
        log_info "ä½¿ç”¨nvprofè¿›è¡Œåˆ†æ..."
        nvprof --log-file "$OUTPUT_DIR/nvprof_output.txt" --print-gpu-trace $TARGET_COMMAND || {
            log_warn "nvprofåˆ†æå¤±è´¥"
        }
    fi
    
    log_info "âœ… CUDAæ€§èƒ½åˆ†æå®Œæˆ"
}

# ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
generate_profiling_report() {
    log_section "ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š"
    
    cat > "$REPORT_FILE" << EOF
# GPUæ€§èƒ½åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è§ˆ
- åˆ†ææ—¶é—´: $(date)
- åˆ†ææŒç»­æ—¶é—´: ${PROFILE_DURATION}ç§’
- é‡‡æ ·é—´éš”: ${SAMPLE_INTERVAL}ç§’
- åˆ†æç±»å‹: $PROFILE_TYPE

## ç³»ç»Ÿç¯å¢ƒ
- æ“ä½œç³»ç»Ÿ: $(uname -a)
- NVIDIAé©±åŠ¨ç‰ˆæœ¬: $(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1)
EOF
    
    if command -v nvcc &> /dev/null; then
        echo "- CUDAç‰ˆæœ¬: $(nvcc --version | grep 'release' | awk '{print $6}' | cut -c2-)" >> "$REPORT_FILE"
    fi
    
    cat >> "$REPORT_FILE" << EOF

## GPUè®¾å¤‡ä¿¡æ¯
\`\`\`
$(nvidia-smi --query-gpu=index,name,memory.total,compute_cap --format=csv)
\`\`\`

## æ€§èƒ½ç›‘æ§ç»“æœ

EOF
    
    # æ·»åŠ ç“¶é¢ˆåˆ†æç»“æœ
    if [[ -f "$OUTPUT_DIR/bottleneck_analysis.json" ]]; then
        echo "### æ€§èƒ½ç“¶é¢ˆåˆ†æ" >> "$REPORT_FILE"
        echo '```json' >> "$REPORT_FILE"
        cat "$OUTPUT_DIR/bottleneck_analysis.json" >> "$REPORT_FILE"
        echo '```' >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi
    
    # æ·»åŠ å†…å­˜åˆ†æç»“æœ
    if [[ -f "$OUTPUT_DIR/memory_analysis.json" ]]; then
        echo "### å†…å­˜ä½¿ç”¨åˆ†æ" >> "$REPORT_FILE"
        echo '```json' >> "$REPORT_FILE"
        cat "$OUTPUT_DIR/memory_analysis.json" >> "$REPORT_FILE"
        echo '```' >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi
    
    # æ·»åŠ æ–‡ä»¶åˆ—è¡¨
    echo "## ç”Ÿæˆçš„æ–‡ä»¶" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
    find "$OUTPUT_DIR" -type f -name "*.csv" -o -name "*.json" -o -name "*.txt" | while read -r file; do
        local filename=$(basename "$file")
        local filesize=$(du -h "$file" | cut -f1)
        echo "- \`$filename\` ($filesize)" >> "$REPORT_FILE"
    done
    
    echo "" >> "$REPORT_FILE"
    echo "## ä¼˜åŒ–å»ºè®®" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
    echo "åŸºäºåˆ†æç»“æœï¼Œå»ºè®®å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š" >> "$REPORT_FILE"
    echo "1. GPUåˆ©ç”¨ç‡ä¼˜åŒ–" >> "$REPORT_FILE"
    echo "2. å†…å­˜ä½¿ç”¨ä¼˜åŒ–" >> "$REPORT_FILE"
    echo "3. æ¸©åº¦å’ŒåŠŸè€—ç®¡ç†" >> "$REPORT_FILE"
    echo "4. æ•°æ®ä¼ è¾“ä¼˜åŒ–" >> "$REPORT_FILE"
    
    log_info "âœ… æ€§èƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ: $REPORT_FILE"
}

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
cleanup_temp_files() {
    log_info "æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
    
    # ä¿ç•™é‡è¦ç»“æœæ–‡ä»¶ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶
    find "$OUTPUT_DIR" -name "*.py" -delete 2>/dev/null || true
    
    log_info "âœ… æ¸…ç†å®Œæˆ"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "GPUæ€§èƒ½åˆ†æè„šæœ¬"
    echo "ç”¨æ³•: $0 [é€‰é¡¹] [åˆ†æç±»å‹]"
    echo ""
    echo "åˆ†æç±»å‹:"
    echo "  basic      åŸºç¡€æ€§èƒ½åˆ†æ"
    echo "  monitor    å®æ—¶ç›‘æ§åˆ†æ"
    echo "  process    è¿›ç¨‹åˆ†æ"
    echo "  memory     å†…å­˜åˆ†æ"
    echo "  bottleneck ç“¶é¢ˆåˆ†æ"
    echo "  cuda       CUDAåˆ†æï¼ˆéœ€è¦ç›®æ ‡å‘½ä»¤ï¼‰"
    echo "  all        æ‰€æœ‰åˆ†æï¼ˆé»˜è®¤ï¼‰"
    echo ""
    echo "é€‰é¡¹:"
    echo "  --duration SECONDS     åˆ†ææŒç»­æ—¶é—´ï¼ˆé»˜è®¤: 60ç§’ï¼‰"
    echo "  --interval SECONDS     é‡‡æ ·é—´éš”ï¼ˆé»˜è®¤: 1ç§’ï¼‰"
    echo "  --output-dir DIR       è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: gpu_profiling_TIMESTAMPï¼‰"
    echo "  --target-pid PID       ç›®æ ‡è¿›ç¨‹PID"
    echo "  --target-command CMD   ç›®æ ‡å‘½ä»¤ï¼ˆç”¨äºCUDAåˆ†æï¼‰"
    echo "  --help                æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0                                    # è¿è¡Œæ‰€æœ‰åˆ†æ"
    echo "  $0 monitor                            # åªè¿è¡Œç›‘æ§åˆ†æ"
    echo "  $0 --duration 120 bottleneck          # è¿è¡Œ120ç§’ç“¶é¢ˆåˆ†æ"
    echo "  $0 --target-command 'python train.py' cuda  # CUDAåˆ†æ"
    echo "  $0 --target-pid 1234 process          # åˆ†æç‰¹å®šè¿›ç¨‹"
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --duration)
                PROFILE_DURATION="$2"
                shift 2
                ;;
            --interval)
                SAMPLE_INTERVAL="$2"
                shift 2
                ;;
            --output-dir)
                OUTPUT_DIR="$2"
                LOG_FILE="$OUTPUT_DIR/profiling.log"
                REPORT_FILE="$OUTPUT_DIR/profiling_report.md"
                shift 2
                ;;
            --target-pid)
                TARGET_PID="$2"
                shift 2
                ;;
            --target-command)
                TARGET_COMMAND="$2"
                shift 2
                ;;
            --help)
                show_help
                exit 0
                ;;
            basic|monitor|process|memory|bottleneck|cuda|all)
                PROFILE_TYPE="$1"
                shift
                ;;
            *)
                log_error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
}

# ä¸»å‡½æ•°
main() {
    local profile_type=${PROFILE_TYPE:-"all"}
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    setup_output_directory
    
    # æ£€æŸ¥ä¾èµ–
    check_dependencies
    
    # æ”¶é›†åŸºç¡€ä¿¡æ¯
    collect_gpu_info
    
    # æ ¹æ®åˆ†æç±»å‹è¿è¡Œç›¸åº”åˆ†æ
    case $profile_type in
        "basic")
            collect_gpu_info
            ;;
        "monitor")
            real_time_monitoring
            ;;
        "process")
            analyze_gpu_processes
            ;;
        "memory")
            analyze_gpu_memory
            ;;
        "bottleneck")
            real_time_monitoring
            analyze_performance_bottlenecks
            ;;
        "cuda")
            cuda_profiling
            ;;
        "all")
            real_time_monitoring
            analyze_gpu_processes
            analyze_gpu_memory
            analyze_performance_bottlenecks
            if [[ -n "$TARGET_COMMAND" ]]; then
                cuda_profiling
            fi
            ;;
        *)
            log_error "æœªçŸ¥åˆ†æç±»å‹: $profile_type"
            show_help
            exit 1
            ;;
    esac
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_profiling_report
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleanup_temp_files
    
    log_info "ğŸ‰ GPUæ€§èƒ½åˆ†æå®Œæˆï¼"
    log_info "åˆ†æç»“æœä¿å­˜åœ¨: $OUTPUT_DIR"
    log_info "è¯¦ç»†æŠ¥å‘Š: $REPORT_FILE"
    
    # æ˜¾ç¤ºå¿«é€Ÿæ‘˜è¦
    if [[ -f "$OUTPUT_DIR/bottleneck_analysis.json" ]]; then
        log_info "\nğŸ“Š å¿«é€Ÿæ‘˜è¦:"
        python3 -c "
import json
try:
    with open('$OUTPUT_DIR/bottleneck_analysis.json', 'r') as f:
        data = json.load(f)
    print(f'GPUå¹³å‡åˆ©ç”¨ç‡: {data[\"gpu_utilization\"][\"mean\"]}%')
    print(f'å†…å­˜å¹³å‡åˆ©ç”¨ç‡: {data[\"memory_utilization\"][\"mean\"]}%')
    if data.get('bottlenecks'):
        print('æ£€æµ‹åˆ°ç“¶é¢ˆ:', ', '.join(data['bottlenecks']))
except: pass
" 2>/dev/null || true
    fi
}

# è§£æå‚æ•°å¹¶è¿è¡Œä¸»å‡½æ•°
parse_arguments "$@"
main