#!/bin/bash
# GPUæ€§èƒ½æµ‹è¯•è„šæœ¬
# æä¾›å…¨é¢çš„GPUæ€§èƒ½æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•åŠŸèƒ½

set -e

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# é…ç½®å˜é‡
TEST_DURATION=60
OUTPUT_DIR="gpu_performance_$(date +%Y%m%d_%H%M%S)"
LOG_FILE="$OUTPUT_DIR/performance_test.log"
REPORT_FILE="$OUTPUT_DIR/performance_report.md"

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1" | tee -a "$LOG_FILE"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$LOG_FILE"
}

log_debug() {
    echo -e "${BLUE}[DEBUG]${NC} $1" | tee -a "$LOG_FILE"
}

# åˆ›å»ºè¾“å‡ºç›®å½•
setup_output_directory() {
    mkdir -p "$OUTPUT_DIR"
    log_info "æµ‹è¯•ç»“æœå°†ä¿å­˜åˆ°: $OUTPUT_DIR"
}

# æ£€æŸ¥GPUç¯å¢ƒ
check_gpu_environment() {
    log_info "æ£€æŸ¥GPUç¯å¢ƒ..."
    
    if ! command -v nvidia-smi &> /dev/null; then
        log_error "nvidia-smiæœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…NVIDIAé©±åŠ¨"
        return 1
    fi
    
    if ! command -v nvcc &> /dev/null; then
        log_warn "nvccæœªæ‰¾åˆ°ï¼ŒæŸäº›æµ‹è¯•å¯èƒ½æ— æ³•è¿è¡Œ"
    fi
    
    # GPUåŸºæœ¬ä¿¡æ¯
    log_info "GPUè®¾å¤‡ä¿¡æ¯:"
    nvidia-smi --query-gpu=index,name,memory.total,compute_cap --format=csv,noheader | tee -a "$LOG_FILE"
    
    # é©±åŠ¨å’ŒCUDAç‰ˆæœ¬
    local driver_version=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1)
    log_info "é©±åŠ¨ç‰ˆæœ¬: $driver_version"
    
    if command -v nvcc &> /dev/null; then
        local cuda_version=$(nvcc --version | grep "release" | awk '{print $6}' | cut -c2-)
        log_info "CUDAç‰ˆæœ¬: $cuda_version"
    fi
    
    log_info "âœ… GPUç¯å¢ƒæ£€æŸ¥å®Œæˆ"
}

# GPUåŸºç¡€æ€§èƒ½æµ‹è¯•
basic_performance_test() {
    log_info "å¼€å§‹GPUåŸºç¡€æ€§èƒ½æµ‹è¯•..."
    
    # GPUåˆ©ç”¨ç‡æµ‹è¯•
    log_info "GPUåˆ©ç”¨ç‡æµ‹è¯•..."
    {
        echo "æ—¶é—´æˆ³,GPUåˆ©ç”¨ç‡(%),å†…å­˜åˆ©ç”¨ç‡(%),æ¸©åº¦(C),åŠŸè€—(W),æ—¶é’Ÿé¢‘ç‡(MHz)"
        for ((i=0; i<30; i++)); do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            local gpu_util=$(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits)
            local mem_util=$(nvidia-smi --query-gpu=utilization.memory --format=csv,noheader,nounits)
            local temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
            local power=$(nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits)
            local clock=$(nvidia-smi --query-gpu=clocks.gr --format=csv,noheader,nounits)
            
            echo "$timestamp,$gpu_util,$mem_util,$temp,$power,$clock"
            sleep 1
        done
    } > "$OUTPUT_DIR/gpu_utilization.csv"
    
    # å†…å­˜å¸¦å®½æµ‹è¯•
    log_info "GPUå†…å­˜å¸¦å®½æµ‹è¯•..."
    if command -v nvidia-smi &> /dev/null; then
        # ä½¿ç”¨nvidia-smiè¿›è¡Œå†…å­˜æµ‹è¯•
        nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv > "$OUTPUT_DIR/memory_info.csv"
    fi
    
    # GPUæ—¶é’Ÿé¢‘ç‡æµ‹è¯•
    log_info "GPUæ—¶é’Ÿé¢‘ç‡æµ‹è¯•..."
    {
        echo "æ—¶é—´æˆ³,å›¾å½¢æ—¶é’Ÿ(MHz),å†…å­˜æ—¶é’Ÿ(MHz),SMæ—¶é’Ÿ(MHz)"
        for ((i=0; i<10; i++)); do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            local gr_clock=$(nvidia-smi --query-gpu=clocks.gr --format=csv,noheader,nounits)
            local mem_clock=$(nvidia-smi --query-gpu=clocks.mem --format=csv,noheader,nounits)
            local sm_clock=$(nvidia-smi --query-gpu=clocks.sm --format=csv,noheader,nounits)
            
            echo "$timestamp,$gr_clock,$mem_clock,$sm_clock"
            sleep 2
        done
    } > "$OUTPUT_DIR/clock_frequencies.csv"
    
    log_info "âœ… GPUåŸºç¡€æ€§èƒ½æµ‹è¯•å®Œæˆ"
}

# CUDAæ€§èƒ½æµ‹è¯•
cuda_performance_test() {
    if ! command -v nvcc &> /dev/null; then
        log_warn "è·³è¿‡CUDAæ€§èƒ½æµ‹è¯•ï¼ˆnvccæœªæ‰¾åˆ°ï¼‰"
        return 0
    fi
    
    log_info "å¼€å§‹CUDAæ€§èƒ½æµ‹è¯•..."
    
    # åˆ›å»ºCUDAæµ‹è¯•ç¨‹åº
    cat > "$OUTPUT_DIR/cuda_benchmark.cu" << 'EOF'
#include <cuda_runtime.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define CHECK_CUDA(call) do { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        printf("CUDA error: %s\n", cudaGetErrorString(err)); \
        exit(1); \
    } \
} while(0)

// çŸ©é˜µä¹˜æ³•æ ¸å‡½æ•°
__global__ void matrixMul(float *a, float *b, float *c, int width) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < width && col < width) {
        float sum = 0.0f;
        for (int k = 0; k < width; k++) {
            sum += a[row * width + k] * b[k * width + col];
        }
        c[row * width + col] = sum;
    }
}

// å‘é‡åŠ æ³•æ ¸å‡½æ•°
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// å†…å­˜å¸¦å®½æµ‹è¯•
void memoryBandwidthTest() {
    printf("\n=== å†…å­˜å¸¦å®½æµ‹è¯• ===\n");
    
    const int sizes[] = {1024, 2048, 4096, 8192};
    const int num_sizes = sizeof(sizes) / sizeof(sizes[0]);
    
    for (int i = 0; i < num_sizes; i++) {
        int n = sizes[i] * sizes[i];
        size_t size = n * sizeof(float);
        
        float *h_data, *d_data;
        CHECK_CUDA(cudaMallocHost(&h_data, size));
        CHECK_CUDA(cudaMalloc(&d_data, size));
        
        // åˆå§‹åŒ–æ•°æ®
        for (int j = 0; j < n; j++) {
            h_data[j] = (float)rand() / RAND_MAX;
        }
        
        // H2Dä¼ è¾“æµ‹è¯•
        cudaEvent_t start, stop;
        CHECK_CUDA(cudaEventCreate(&start));
        CHECK_CUDA(cudaEventCreate(&stop));
        
        CHECK_CUDA(cudaEventRecord(start));
        CHECK_CUDA(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));
        CHECK_CUDA(cudaEventRecord(stop));
        CHECK_CUDA(cudaEventSynchronize(stop));
        
        float h2d_time;
        CHECK_CUDA(cudaEventElapsedTime(&h2d_time, start, stop));
        float h2d_bandwidth = (size / 1e9) / (h2d_time / 1000.0);
        
        // D2Hä¼ è¾“æµ‹è¯•
        CHECK_CUDA(cudaEventRecord(start));
        CHECK_CUDA(cudaMemcpy(h_data, d_data, size, cudaMemcpyDeviceToHost));
        CHECK_CUDA(cudaEventRecord(stop));
        CHECK_CUDA(cudaEventSynchronize(stop));
        
        float d2h_time;
        CHECK_CUDA(cudaEventElapsedTime(&d2h_time, start, stop));
        float d2h_bandwidth = (size / 1e9) / (d2h_time / 1000.0);
        
        printf("çŸ©é˜µå¤§å°: %dx%d, H2D: %.2f GB/s, D2H: %.2f GB/s\n", 
               sizes[i], sizes[i], h2d_bandwidth, d2h_bandwidth);
        
        CHECK_CUDA(cudaEventDestroy(start));
        CHECK_CUDA(cudaEventDestroy(stop));
        CHECK_CUDA(cudaFreeHost(h_data));
        CHECK_CUDA(cudaFree(d_data));
    }
}

// è®¡ç®—æ€§èƒ½æµ‹è¯•
void computePerformanceTest() {
    printf("\n=== è®¡ç®—æ€§èƒ½æµ‹è¯• ===\n");
    
    const int sizes[] = {512, 1024, 2048, 4096};
    const int num_sizes = sizeof(sizes) / sizeof(sizes[0]);
    
    for (int i = 0; i < num_sizes; i++) {
        int width = sizes[i];
        int n = width * width;
        size_t size = n * sizeof(float);
        
        float *h_a, *h_b, *h_c;
        float *d_a, *d_b, *d_c;
        
        // åˆ†é…å†…å­˜
        CHECK_CUDA(cudaMallocHost(&h_a, size));
        CHECK_CUDA(cudaMallocHost(&h_b, size));
        CHECK_CUDA(cudaMallocHost(&h_c, size));
        CHECK_CUDA(cudaMalloc(&d_a, size));
        CHECK_CUDA(cudaMalloc(&d_b, size));
        CHECK_CUDA(cudaMalloc(&d_c, size));
        
        // åˆå§‹åŒ–æ•°æ®
        for (int j = 0; j < n; j++) {
            h_a[j] = (float)rand() / RAND_MAX;
            h_b[j] = (float)rand() / RAND_MAX;
        }
        
        // å¤åˆ¶æ•°æ®åˆ°GPU
        CHECK_CUDA(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));
        CHECK_CUDA(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));
        
        // çŸ©é˜µä¹˜æ³•æµ‹è¯•
        dim3 blockSize(16, 16);
        dim3 gridSize((width + blockSize.x - 1) / blockSize.x, 
                      (width + blockSize.y - 1) / blockSize.y);
        
        cudaEvent_t start, stop;
        CHECK_CUDA(cudaEventCreate(&start));
        CHECK_CUDA(cudaEventCreate(&stop));
        
        // é¢„çƒ­
        matrixMul<<<gridSize, blockSize>>>(d_a, d_b, d_c, width);
        CHECK_CUDA(cudaDeviceSynchronize());
        
        // æ€§èƒ½æµ‹è¯•
        CHECK_CUDA(cudaEventRecord(start));
        matrixMul<<<gridSize, blockSize>>>(d_a, d_b, d_c, width);
        CHECK_CUDA(cudaEventRecord(stop));
        CHECK_CUDA(cudaEventSynchronize(stop));
        
        float elapsed_time;
        CHECK_CUDA(cudaEventElapsedTime(&elapsed_time, start, stop));
        
        // è®¡ç®—GFLOPS
        double flops = 2.0 * width * width * width;
        double gflops = flops / (elapsed_time / 1000.0) / 1e9;
        
        printf("çŸ©é˜µå¤§å°: %dx%d, æ—¶é—´: %.2f ms, æ€§èƒ½: %.2f GFLOPS\n", 
               width, width, elapsed_time, gflops);
        
        // æ¸…ç†èµ„æº
        CHECK_CUDA(cudaEventDestroy(start));
        CHECK_CUDA(cudaEventDestroy(stop));
        CHECK_CUDA(cudaFreeHost(h_a));
        CHECK_CUDA(cudaFreeHost(h_b));
        CHECK_CUDA(cudaFreeHost(h_c));
        CHECK_CUDA(cudaFree(d_a));
        CHECK_CUDA(cudaFree(d_b));
        CHECK_CUDA(cudaFree(d_c));
    }
}

int main() {
    printf("CUDAæ€§èƒ½åŸºå‡†æµ‹è¯•\n");
    
    // è®¾å¤‡ä¿¡æ¯
    cudaDeviceProp prop;
    CHECK_CUDA(cudaGetDeviceProperties(&prop, 0));
    printf("è®¾å¤‡: %s\n", prop.name);
    printf("è®¡ç®—èƒ½åŠ›: %d.%d\n", prop.major, prop.minor);
    printf("å…¨å±€å†…å­˜: %.2f GB\n", prop.totalGlobalMem / 1024.0 / 1024.0 / 1024.0);
    printf("å¤šå¤„ç†å™¨æ•°é‡: %d\n", prop.multiProcessorCount);
    printf("æœ€å¤§çº¿ç¨‹æ•°/å—: %d\n", prop.maxThreadsPerBlock);
    
    memoryBandwidthTest();
    computePerformanceTest();
    
    printf("\nâœ… CUDAæ€§èƒ½æµ‹è¯•å®Œæˆ\n");
    return 0;
}
EOF
    
    # ç¼–è¯‘å’Œè¿è¡ŒCUDAæµ‹è¯•
    log_info "ç¼–è¯‘CUDAæµ‹è¯•ç¨‹åº..."
    if nvcc -O3 -o "$OUTPUT_DIR/cuda_benchmark" "$OUTPUT_DIR/cuda_benchmark.cu"; then
        log_info "è¿è¡ŒCUDAæ€§èƒ½æµ‹è¯•..."
        "$OUTPUT_DIR/cuda_benchmark" > "$OUTPUT_DIR/cuda_performance.log" 2>&1
        log_info "âœ… CUDAæ€§èƒ½æµ‹è¯•å®Œæˆ"
    else
        log_error "CUDAæµ‹è¯•ç¨‹åºç¼–è¯‘å¤±è´¥"
    fi
}

# PyTorchæ€§èƒ½æµ‹è¯•
pytorch_performance_test() {
    log_info "å¼€å§‹PyTorchæ€§èƒ½æµ‹è¯•..."
    
    # åˆ›å»ºPyTorchæµ‹è¯•è„šæœ¬
    cat > "$OUTPUT_DIR/pytorch_benchmark.py" << 'EOF'
import torch
import time
import numpy as np

def test_pytorch_performance():
    print("PyTorch GPUæ€§èƒ½æµ‹è¯•")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if not torch.cuda.is_available():
        print("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda')
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    
    # çŸ©é˜µä¹˜æ³•æµ‹è¯•
    print("\n=== çŸ©é˜µä¹˜æ³•æ€§èƒ½æµ‹è¯• ===")
    sizes = [512, 1024, 2048, 4096]
    
    for size in sizes:
        # åˆ›å»ºéšæœºçŸ©é˜µ
        a = torch.randn(size, size, device=device)
        b = torch.randn(size, size, device=device)
        
        # é¢„çƒ­
        torch.mm(a, b)
        torch.cuda.synchronize()
        
        # æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        for _ in range(10):
            c = torch.mm(a, b)
        torch.cuda.synchronize()
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 10
        flops = 2 * size**3
        gflops = flops / avg_time / 1e9
        
        print(f"çŸ©é˜µå¤§å°: {size}x{size}, å¹³å‡æ—¶é—´: {avg_time*1000:.2f} ms, æ€§èƒ½: {gflops:.2f} GFLOPS")
    
    # å·ç§¯æµ‹è¯•
    print("\n=== å·ç§¯æ€§èƒ½æµ‹è¯• ===")
    batch_sizes = [1, 4, 8, 16]
    
    for batch_size in batch_sizes:
        # åˆ›å»ºè¾“å…¥å’Œå·ç§¯å±‚
        input_tensor = torch.randn(batch_size, 3, 224, 224, device=device)
        conv_layer = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1).to(device)
        
        # é¢„çƒ­
        conv_layer(input_tensor)
        torch.cuda.synchronize()
        
        # æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        for _ in range(100):
            output = conv_layer(input_tensor)
        torch.cuda.synchronize()
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 100
        throughput = batch_size / avg_time
        
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}, å¹³å‡æ—¶é—´: {avg_time*1000:.2f} ms, ååé‡: {throughput:.2f} samples/s")
    
    # å†…å­˜å¸¦å®½æµ‹è¯•
    print("\n=== å†…å­˜å¸¦å®½æµ‹è¯• ===")
    sizes = [1024*1024, 4*1024*1024, 16*1024*1024, 64*1024*1024]
    
    for size in sizes:
        # åˆ›å»ºå¤§å¼ é‡
        data = torch.randn(size, device='cpu')
        
        # H2Dä¼ è¾“æµ‹è¯•
        start_time = time.time()
        gpu_data = data.to(device)
        torch.cuda.synchronize()
        h2d_time = time.time() - start_time
        
        # D2Hä¼ è¾“æµ‹è¯•
        start_time = time.time()
        cpu_data = gpu_data.to('cpu')
        torch.cuda.synchronize()
        d2h_time = time.time() - start_time
        
        data_size_gb = size * 4 / 1024**3  # float32 = 4 bytes
        h2d_bandwidth = data_size_gb / h2d_time
        d2h_bandwidth = data_size_gb / d2h_time
        
        print(f"æ•°æ®å¤§å°: {data_size_gb:.2f} GB, H2D: {h2d_bandwidth:.2f} GB/s, D2H: {d2h_bandwidth:.2f} GB/s")

if __name__ == "__main__":
    test_pytorch_performance()
EOF
    
    # è¿è¡ŒPyTorchæµ‹è¯•
    if command -v python3 &> /dev/null; then
        log_info "è¿è¡ŒPyTorchæ€§èƒ½æµ‹è¯•..."
        python3 "$OUTPUT_DIR/pytorch_benchmark.py" > "$OUTPUT_DIR/pytorch_performance.log" 2>&1 || log_warn "PyTorchæµ‹è¯•å¯èƒ½å¤±è´¥ï¼ˆéœ€è¦å®‰è£…PyTorchï¼‰"
    else
        log_warn "è·³è¿‡PyTorchæµ‹è¯•ï¼ˆpython3æœªæ‰¾åˆ°ï¼‰"
    fi
    
    log_info "âœ… PyTorchæ€§èƒ½æµ‹è¯•å®Œæˆ"
}

# å‹åŠ›æµ‹è¯•
stress_test() {
    log_info "å¼€å§‹GPUå‹åŠ›æµ‹è¯•..."
    
    # åˆ›å»ºå‹åŠ›æµ‹è¯•è„šæœ¬
    cat > "$OUTPUT_DIR/gpu_stress_test.py" << 'EOF'
import subprocess
import time
import threading
import signal
import sys

class GPUStressTest:
    def __init__(self, duration=300):
        self.duration = duration
        self.running = True
        self.results = []
    
    def monitor_gpu(self):
        """ç›‘æ§GPUçŠ¶æ€"""
        while self.running:
            try:
                result = subprocess.run([
                    'nvidia-smi', 
                    '--query-gpu=timestamp,temperature.gpu,utilization.gpu,memory.used,power.draw',
                    '--format=csv,noheader,nounits'
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    self.results.append(result.stdout.strip())
                
                time.sleep(1)
            except Exception as e:
                print(f"ç›‘æ§é”™è¯¯: {e}")
                break
    
    def stress_computation(self):
        """GPUè®¡ç®—å‹åŠ›æµ‹è¯•"""
        try:
            import torch
            if torch.cuda.is_available():
                device = torch.device('cuda')
                print("å¼€å§‹GPUè®¡ç®—å‹åŠ›æµ‹è¯•...")
                
                while self.running:
                    # å¤§çŸ©é˜µä¹˜æ³•
                    a = torch.randn(2048, 2048, device=device)
                    b = torch.randn(2048, 2048, device=device)
                    c = torch.mm(a, b)
                    
                    # å·ç§¯æ“ä½œ
                    x = torch.randn(32, 3, 224, 224, device=device)
                    conv = torch.nn.Conv2d(3, 64, 3, padding=1).to(device)
                    y = conv(x)
                    
                    del a, b, c, x, y
                    torch.cuda.empty_cache()
        except ImportError:
            print("PyTorchæœªå®‰è£…ï¼Œè·³è¿‡è®¡ç®—å‹åŠ›æµ‹è¯•")
        except Exception as e:
            print(f"è®¡ç®—å‹åŠ›æµ‹è¯•é”™è¯¯: {e}")
    
    def run_test(self):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"å¼€å§‹GPUå‹åŠ›æµ‹è¯•ï¼ŒæŒç»­æ—¶é—´: {self.duration} ç§’")
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self.monitor_gpu)
        monitor_thread.start()
        
        # å¯åŠ¨å‹åŠ›æµ‹è¯•çº¿ç¨‹
        stress_thread = threading.Thread(target=self.stress_computation)
        stress_thread.start()
        
        # ç­‰å¾…æµ‹è¯•å®Œæˆ
        time.sleep(self.duration)
        
        # åœæ­¢æµ‹è¯•
        self.running = False
        monitor_thread.join(timeout=5)
        stress_thread.join(timeout=5)
        
        # ä¿å­˜ç»“æœ
        with open('gpu_stress_results.csv', 'w') as f:
            f.write('timestamp,temperature,utilization,memory_used,power_draw\n')
            for result in self.results:
                f.write(result + '\n')
        
        print(f"å‹åŠ›æµ‹è¯•å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: gpu_stress_results.csv")
        
        # åˆ†æç»“æœ
        self.analyze_results()
    
    def analyze_results(self):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not self.results:
            print("æ²¡æœ‰æµ‹è¯•æ•°æ®")
            return
        
        temps = []
        utils = []
        powers = []
        
        for line in self.results:
            parts = line.split(',')
            if len(parts) >= 5:
                try:
                    temps.append(float(parts[1]))
                    utils.append(float(parts[2]))
                    powers.append(float(parts[4]))
                except ValueError:
                    continue
        
        if temps and utils and powers:
            print("\n=== å‹åŠ›æµ‹è¯•åˆ†æç»“æœ ===")
            print(f"å¹³å‡æ¸©åº¦: {sum(temps)/len(temps):.1f}Â°C")
            print(f"æœ€é«˜æ¸©åº¦: {max(temps):.1f}Â°C")
            print(f"å¹³å‡GPUåˆ©ç”¨ç‡: {sum(utils)/len(utils):.1f}%")
            print(f"å¹³å‡åŠŸè€—: {sum(powers)/len(powers):.1f}W")
            print(f"æœ€é«˜åŠŸè€—: {max(powers):.1f}W")

def signal_handler(sig, frame):
    print('\næµ‹è¯•è¢«ä¸­æ–­')
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    
    duration = 60  # é»˜è®¤60ç§’
    if len(sys.argv) > 1:
        duration = int(sys.argv[1])
    
    test = GPUStressTest(duration)
    test.run_test()
EOF
    
    # è¿è¡Œå‹åŠ›æµ‹è¯•
    if command -v python3 &> /dev/null; then
        log_info "è¿è¡ŒGPUå‹åŠ›æµ‹è¯• (60ç§’)..."
        cd "$OUTPUT_DIR"
        python3 gpu_stress_test.py 60
        cd - > /dev/null
        log_info "âœ… GPUå‹åŠ›æµ‹è¯•å®Œæˆ"
    else
        log_warn "è·³è¿‡å‹åŠ›æµ‹è¯•ï¼ˆpython3æœªæ‰¾åˆ°ï¼‰"
    fi
}

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
generate_performance_report() {
    log_info "ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š..."
    
    cat > "$REPORT_FILE" << EOF
# GPUæ€§èƒ½æµ‹è¯•æŠ¥å‘Š

## æµ‹è¯•ç¯å¢ƒ
- æµ‹è¯•æ—¶é—´: $(date)
- æ“ä½œç³»ç»Ÿ: $(uname -a)
- GPUé©±åŠ¨ç‰ˆæœ¬: $(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1)
EOF
    
    if command -v nvcc &> /dev/null; then
        echo "- CUDAç‰ˆæœ¬: $(nvcc --version | grep 'release' | awk '{print $6}' | cut -c2-)" >> "$REPORT_FILE"
    fi
    
    cat >> "$REPORT_FILE" << EOF

## GPUè®¾å¤‡ä¿¡æ¯
\`\`\`
$(nvidia-smi --query-gpu=index,name,memory.total,compute_cap --format=csv)
\`\`\`

## æµ‹è¯•ç»“æœ

EOF
    
    # æ·»åŠ å„é¡¹æµ‹è¯•ç»“æœ
    if [[ -f "$OUTPUT_DIR/cuda_performance.log" ]]; then
        echo "### CUDAæ€§èƒ½æµ‹è¯•" >> "$REPORT_FILE"
        echo '```' >> "$REPORT_FILE"
        cat "$OUTPUT_DIR/cuda_performance.log" >> "$REPORT_FILE"
        echo '```' >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi
    
    if [[ -f "$OUTPUT_DIR/pytorch_performance.log" ]]; then
        echo "### PyTorchæ€§èƒ½æµ‹è¯•" >> "$REPORT_FILE"
        echo '```' >> "$REPORT_FILE"
        cat "$OUTPUT_DIR/pytorch_performance.log" >> "$REPORT_FILE"
        echo '```' >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi
    
    if [[ -f "$OUTPUT_DIR/gpu_stress_results.csv" ]]; then
        echo "### å‹åŠ›æµ‹è¯•ç»“æœ" >> "$REPORT_FILE"
        echo "å‹åŠ›æµ‹è¯•æ•°æ®ä¿å­˜åœ¨: gpu_stress_results.csv" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi
    
    log_info "âœ… æ€§èƒ½æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ: $REPORT_FILE"
}

# æ¸…ç†æµ‹è¯•æ–‡ä»¶
cleanup_test_files() {
    log_info "æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
    
    # ä¿ç•™é‡è¦ç»“æœæ–‡ä»¶ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶
    find "$OUTPUT_DIR" -name "*.cu" -delete 2>/dev/null || true
    find "$OUTPUT_DIR" -name "cuda_benchmark" -delete 2>/dev/null || true
    
    log_info "âœ… æ¸…ç†å®Œæˆ"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "GPUæ€§èƒ½æµ‹è¯•è„šæœ¬"
    echo "ç”¨æ³•: $0 [é€‰é¡¹] [æµ‹è¯•ç±»å‹]"
    echo ""
    echo "æµ‹è¯•ç±»å‹:"
    echo "  basic      åŸºç¡€æ€§èƒ½æµ‹è¯•"
    echo "  cuda       CUDAæ€§èƒ½æµ‹è¯•"
    echo "  pytorch    PyTorchæ€§èƒ½æµ‹è¯•"
    echo "  stress     GPUå‹åŠ›æµ‹è¯•"
    echo "  all        æ‰€æœ‰æµ‹è¯•ï¼ˆé»˜è®¤ï¼‰"
    echo ""
    echo "é€‰é¡¹:"
    echo "  --duration SECONDS    æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆé»˜è®¤: 60ç§’ï¼‰"
    echo "  --output-dir DIR      è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: gpu_performance_TIMESTAMPï¼‰"
    echo "  --help               æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0                           # è¿è¡Œæ‰€æœ‰æµ‹è¯•"
    echo "  $0 basic                     # åªè¿è¡ŒåŸºç¡€æµ‹è¯•"
    echo "  $0 --duration 120 stress     # è¿è¡Œ120ç§’å‹åŠ›æµ‹è¯•"
    echo "  $0 --output-dir my_test all  # æŒ‡å®šè¾“å‡ºç›®å½•"
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --duration)
                TEST_DURATION="$2"
                shift 2
                ;;
            --output-dir)
                OUTPUT_DIR="$2"
                LOG_FILE="$OUTPUT_DIR/performance_test.log"
                REPORT_FILE="$OUTPUT_DIR/performance_report.md"
                shift 2
                ;;
            --help)
                show_help
                exit 0
                ;;
            basic|cuda|pytorch|stress|all)
                TEST_TYPE="$1"
                shift
                ;;
            *)
                log_error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
}

# ä¸»å‡½æ•°
main() {
    local test_type=${TEST_TYPE:-"all"}
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    setup_output_directory
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_gpu_environment
    
    # æ ¹æ®æµ‹è¯•ç±»å‹è¿è¡Œç›¸åº”æµ‹è¯•
    case $test_type in
        "basic")
            basic_performance_test
            ;;
        "cuda")
            cuda_performance_test
            ;;
        "pytorch")
            pytorch_performance_test
            ;;
        "stress")
            stress_test
            ;;
        "all")
            basic_performance_test
            cuda_performance_test
            pytorch_performance_test
            stress_test
            ;;
        *)
            log_error "æœªçŸ¥æµ‹è¯•ç±»å‹: $test_type"
            show_help
            exit 1
            ;;
    esac
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_performance_report
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleanup_test_files
    
    log_info "ğŸ‰ GPUæ€§èƒ½æµ‹è¯•å®Œæˆï¼"
    log_info "æµ‹è¯•ç»“æœä¿å­˜åœ¨: $OUTPUT_DIR"
    log_info "è¯¦ç»†æŠ¥å‘Š: $REPORT_FILE"
}

# è§£æå‚æ•°å¹¶è¿è¡Œä¸»å‡½æ•°
parse_arguments "$@"
main